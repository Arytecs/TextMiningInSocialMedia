load("totr.Rdata")
head(tot)
dat<-tot
fecha<-paste(as.character(dat[,1]),as.character(dat[,2]),as.character(dat[,3]),sep="-")
dat$fecha<-fecha
sum(is.na(dat$estat))
atasco = rep(0,length(dat$estat))
atasco [which(dat$estat==1)]<-1
atasco [which(dat$estat==2)]<-1
atasco [which(dat$estat>3)]<-NA
dat$atasco<-atasco
dat<-subset(dat,is.na(atasco)==FALSE)
load("totr.Rdata")
head(tot)
dat<-tot
fecha<-paste(as.character(dat[,1]),as.character(dat[,2]),as.character(dat[,3]),sep="-")
dat$fecha<-fecha
dat$fecha<-as.Date(dat$fecha)
sum(is.na(dat$estat))
atasco = rep(0,length(dat$estat))
atasco [which(dat$estat==1)]<-1
atasco [which(dat$estat==2)]<-1
atasco [which(dat$estat>3)]<-NA
dat$atasco<-atasco
dat<-subset(dat,is.na(atasco)==FALSE)
estadoAtasco<-by(dat[,"atasco"], dat$fecha, mean)
which.max(estadoAtasco)
max(estadoAtasco)
tramos.medias<-by(dat[,"atasco"], dat$id, dat$carrer, mean)
tramos.medias<-by(dat[,"atasco"], dat$id, mean)
max(tramos.medias)
maxValue<-which.max(tramos.medias)
tramos.medias[as.integer(maxValue)]
as.integer(maxValue)
dat[dat$id==maxValue,"carrer"][1]
maxValue
maxValue<-tramos.medias[as.integer(maxValue)]
maxValue<-tramos.medias[as.integer(maxValue)]
maxValue
maxValue<-which.max(tramos.medias)
maxValue<-tramos.medias[as.integer(maxValue)]
maxValue
maxValue[0]
maxValue[1]
dat[dat$id==maxValue,"carrer"][1]
dat[dat$id==22,"carrer"][1]
diaSemana<-as.POSIXlt(dat$fecha)$wday
dat$diaSem<-diaSemana
summary(dat)
View(dat)
View(dat)
diaSemana.media<-by(dat[,"atasco"], dat$diaSem, mean)
which.max(diaSemana)
which.max(diaSemana.media)
which.min(diaSemana.media)
dat[dat$diaSem==0]
dat[dat$diaSem==0,"fecha"]
library(qdap)
library(XML)
install.packages(qdap)
install.packages("qdap")
install.packages("XML")
version
install.packages("tm")
install.packages("splitstackshap")
install.packages("tm")
install.packages('devtools')
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
updateR(admin_password = 'Admin user password')
install.packages(as.vector(needed_packages))
version
version
install.packages("tm")
install.packages("splitstackshap")
library(devtools)
install_github("mrdwab/splitstackshape", ref = "v2.0")
install.packages("devtools")
library(devtools)
install_github("mrdwab/splitstackshape", ref = "v2.0")
install.packages("caret")
library(qdap)
library(XML)
install.packages("qdap")
library(qdap)
version
install.packages("qdap")
library(qdap)
library(devtools)
install_github("mrdwab/splitstackshape", ref = "v2.0")
install.packages("qdap")
install.packages("XML")
install.packages("tm")
install.packages("splitstackshap")
install.packages("caret")
library(qdap)
library(XML)
library(tm)
library(splitstackshape)
library(caret)
start.time <- Sys.time()
n <- 10
lang <- "es"
path_training <- "/home/kicorangel/bigdata2018/pan-ap17-bigdata/training"		# Your training path
path_test <- "/home/kicorangel/bigdata2018/pan-ap17-bigdata/test"							# Your test path
k <- 3
r <- 1
GenerateVocabulary <- function(path, n = 1000, lowcase = TRUE, punctuations = TRUE, numbers = TRUE, whitespaces = TRUE, swlang = "", swlist = "", verbose = TRUE) {
setwd(path)
# Reading corpus list of files
files = list.files(pattern="*.xml")
# Reading files contents and concatenating into the corpus.raw variable
corpus.raw <- NULL
i <- 0
for (file in files) {
xmlfile <- xmlTreeParse(file, useInternalNodes = TRUE)
corpus.raw <- c(corpus.raw, xpathApply(xmlfile, "//document", function(x) xmlValue(x)))
i <- i + 1
if (verbose) print(paste(i, " ", file))
}
# Preprocessing the corpus
corpus.preprocessed <- corpus.raw
if (lowcase) {
if (verbose) print("Tolower...")
corpus.preprocessed <- tolower(corpus.preprocessed)
}
if (punctuations) {
if (verbose) print("Removing punctuations...")
corpus.preprocessed <- removePunctuation(corpus.preprocessed)
}
if (numbers) {
if (verbose) print("Removing numbers...")
corpus.preprocessed <- removeNumbers(corpus.preprocessed)
}
if (whitespaces) {
if (verbose) print("Stripping whitestpaces...")
corpus.preprocessed <- stripWhitespace(corpus.preprocessed)
}
if (swlang!="")	{
if (verbose) print(paste("Removing stopwords for language ", swlang , "..."))
corpus.preprocessed <- removeWords(corpus.preprocessed, stopwords(swlang))
}
if (swlist!="") {
if (verbose) print("Removing provided stopwords...")
corpus.preprocessed <- removeWords(corpus.preprocessed, swlist)
}
# Generating the vocabulary as the n most frequent terms
if (verbose) print("Generating frequency terms")
corpus.frequentterms <- freq_terms(corpus.preprocessed, n)
if (verbose) plot(corpus.frequentterms)
return (corpus.frequentterms)
}
# GenerateBoW: Given a corpus (training or test), and a vocabulary, obtains the bow representation
GenerateBoW <- function(path, vocabulary, n = 100000, lowcase = TRUE, punctuations = TRUE, numbers = TRUE, whitespaces = TRUE, swlang = "", swlist = "", class="variety", verbose = TRUE) {
setwd(path)
# Reading the truth file
truth <- read.csv("truth.txt", sep=":", header=FALSE)
truth <- truth[,c(1,4,7)]
colnames(truth) <- c("author", "gender", "variety")
i <- 0
bow <- NULL
# Reading the list of files in the corpus
files = list.files(pattern="*.xml")
for (file in files) {
# Obtaining truth information for the current author
author <- gsub(".xml", "", file)
variety <- truth[truth$author==author,"variety"]
gender <- truth[truth$author==author,"gender"]
# Reading contents for the current author
xmlfile <- xmlTreeParse(file, useInternalNodes = TRUE)
txtdata <- xpathApply(xmlfile, "//document", function(x) xmlValue(x))
# Preprocessing the text
if (lowcase) {
txtdata <- tolower(txtdata)
}
if (punctuations) {
txtdata <- removePunctuation(txtdata)
}
if (numbers) {
txtdata <- removeNumbers(txtdata)
}
if (whitespaces) {
txtdata <- stripWhitespace(txtdata)
}
# Building the vector space model. For each word in the vocabulary, it obtains the frequency of occurrence in the current author.
line <- author
freq <- freq_terms(txtdata, n)
for (word in vocabulary$WORD) {
thefreq <- 0
if (length(freq[freq$WORD==word,"FREQ"])>0) {
thefreq <- freq[freq$WORD==word,"FREQ"]
}
line <- paste(line, ",", thefreq, sep="")
}
# Concatenating the corresponding class: variety or gender
if (class=="variety") {
line <- paste(variety, ",", line, sep="")
} else {
line <- paste(gender, ",", line, sep="")
}
# New row in the vector space model matrix
bow <- rbind(bow, line)
i <- i + 1
if (verbose) {
if (class=="variety") {
print(paste(i, author, variety))
} else {
print(paste(i, author, gender))
}
}
}
return (bow)
}
vocabulary <- GenerateVocabulary(path_training, n, swlang=lang)
path_training <- "training"    # Your training path
path_test <- "test"							# Your test path
vocabulary <- GenerateVocabulary(path_training, n)
setwd("~/Documents/TextMiningInSocialMedia/code")
path_training <- "./training"    # Your training path
path_test <- "./test"							# Your test path
vocabulary <- GenerateVocabulary(path_training, n)
install.packages('devtools')
install.packages("devtools")
library(devtools)
install_github('andreacirilloac/updateR')
library(updateR)
updateR(admin_password = 'victor99')
install.packages(as.vector(needed_packages))
library(qdap)
install.packages("devtools")
library(qdap)
install.packages("rcurl")
install.packages("RCurl")
library(qdap)
install.packages("qdapTools")
library(qdap)
uninstall.packages(RCurl)
require(plyr)
install.packages("pylr")
install.packages("plyr")
require(plyr)
update.packages(checkBuilt=TRUE, ask=FALSE)
library(qdap)
install.packages("dylib")
